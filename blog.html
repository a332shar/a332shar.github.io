<!DOCTYPE html>
<html >
<head>
  <meta charset="UTF-8">
  <title>Revolution Robotics</title>
  <link rel="shortcut icon" type="image/png" href="img/favicon.png"/>
  
  
  
      <link rel="stylesheet" href="css/blogstyle.css">

  
</head>

<body>
  
<header>
  <div class="small" id="header-scroll">
    <h1><a href="#home">REVOLUTION ROBOTICS</a></h1>
    <nav>
      <ul>
        <li><a href="index.html#home">HOME</a></li>
      </ul>
    </nav>
  </div>
</header>

<article id="blog" class="content dark">
  <header class="title one fade">BLOG</header>
  <div class="spacer"></div>
  <div class="title two fade">Find our about our
     progress by scolling through our blog updates
     below!</div>
  
     <div id="work" class="work-container">

      <div id="update-16" class="work-exp">
        <div class="tag-project">UPDATE 16</div>
        <div class="title-project">FINAL DRAFT OF ADVERTISEMENT</div>
        <div class="project-date">MAR 15, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Using the footage taken from around campus and stock footage, the advertisement video was narrated and edited into a first draft for the symposium. From feedback from teammates some changes will be made before the symposium.</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-15" class="work-exp">
        <div class="tag-project">UPDATE 15</div>
        <div class="title-project">FINAL DRAFT OF POSTER AND RESIZE</div>
        <div class="project-date">MAR 15, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>To prepare the poster for printing the final changes were made. A high-resolution image of the robot with the attached cameras was created to illustrate the integrated system which is shown in the principles of operations section. Due to an issue with the aspect ratio of the poster it had to be reconfigured to fit a printable paper size. The poster was submit to be print.</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-14" class="work-exp">
        <div class="tag-project">UPDATE 14</div>
        <div class="title-project">TEAM FILMING SESSION</div>
        <div class="project-date">MAR 14, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Team met to film video segments for the advertisement video, making some adjustments to the script as necessary. Footage of spoken parts were recorded around campus and background video for narrated parts were taken of the robot setup and operation.</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      

      <div id="update-13" class="work-exp">
        <div class="tag-project">UPDATE 13</div>
        <div class="title-project">POSTER CONTENT CREATED</div>
        <div class="project-date">MAR 13, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Edited the previous draft of the poster to include content, statistics and images gathered during product development and verification. Added logos for technology used in the product and references. Some changes were recommended by team to be made at a future date.</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-12" class="work-exp">
        <div class="tag-project">UPDATE 12</div>
        <div class="title-project">SYSTEM TESTING PERFORMED</div>
        <div class="project-date">MAR 12, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Testing of the developed system was performed in advance of the symposium to ensure a robust, functional system could be displayed. These tests included the fine-tuning of octomap resolution and the scope of the pass-through filters to ensure response time was sufficient for a presentation.</p>
        </div>
      </div>

      <div id="update-11" class="work-exp">
        <div class="tag-project">UPDATE 11</div>
        <div class="title-project">CREATED DRAFT OF POSTER</div>
        <div class="project-date">MAR 11, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Draft of the poster, including placeholder content and images, was created to verify with group whether the layout was sufficient and that all the requirements could be met. After a brief brainstorming session some notes for changes were made for a future date. The poster draft was made using Microsoft Powerpoint.
          </p>
          <h2>Photo</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-10" class="work-exp">
        <div class="tag-project">UPDATE 10</div>
        <div class="title-project">PROCESS INTEGRATION FOR ALL STEPS COMPLETED</div>
        <div class="project-date">MAR 10, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>Using each of the previously developed algorithms and components of the mapping process, full integration between multiple cameras to creating a new robot path was completed. During testing at this phase of the project it was determined that managing the pointclouds and octomaps required too much processing. To solve this, the scope of the cameras was reduced with six pass-through filters which removes all the data not in an area which needs to be monitored. This implementation improved the processing requirements to an acceptable level.</p>
          <h2>Photo</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>
      
      <div id="update-9" class="work-exp">
        <div class="tag-project">UPDATE 9</div>
        <div class="title-project">CREATED FINAL DRAFT OF MECHANICAL MOUNTS</div>
        <div class="project-date">MAR 09, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>From the drafts previously created the final version of the mounts has been developed in Solidworks. Due to the configuration of the lab robot, including a custom base to restrict movement, testing is being performed using adjustable clamps instead of the designed mounts. Mounts would be a part of the final product, however they may be excluded from simulations and presentations until the development is the software is complete.</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-8" class="work-exp">
        <div class="tag-project">UPDATE 8</div>
        <div class="title-project">MULTIPLE CAMERA CAPABILITY IMPLEMENTED</div>
        <div class="project-date">FEB 23, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>A custom C++ algorithm was developed to process and combine pointclouds so that several cameras can be mounted to one robot, which is required to have an acceptable range of vision for industrial settings. This software transforms, filters and concatenates several pointclouds into one pointcloud which can be managed in the same way as a single-camera system. Developing this algorithm greatly increases the processing requirements and required significant testing and debugging to operate at a level of quality acceptable for this application.</p>
        </div>
      </div>

      <div id="update-7" class="work-exp">
        <div class="tag-project">UPDATE 7</div>
        <div class="title-project">REPATHING ALGORITHM SET UP</div>
        <div class="project-date">FEB 6, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>The pathing technique Rapid-exploring Random Tree (RRT) was implemented. This algorithm quickly finds a new path between two intended points while avoiding defined obstacles which block the optimal path. Using the OctoMaps received from the server this enables the robot to react to objects detected using one Intel RealSense camera. Roboguide can be used to simulate this path.</p>
          <h2>Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>

      <div id="update-6" class="work-exp">
        <div class="tag-project">UPDATE 6</div>
        <div class="title-project">ADDED ADJUSTABILITY TO MOUNTS</div>
        <div class="project-date">FEB 4, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
            <p>To support calibration, the mounts have been broken down into the camera mount and the robotic arm mounts. This allows for a more general-use design to be developed for more models of robots. They can be adjusted with one axis of rotation, and fixed in the adjusted angle using a bolt and screw. A future iteration will have better rotational options.
            </p>
          <h2>Images</h2>
          <p><img src="img/part1.png" width="60%" height="400" frameborder="0">
          <p><img src="img/part2.png" width="60%" height="400" frameborder="0"></p></p>
        </div>
      </div>

    <div id="update-5" class="work-exp">
      <div class="tag-project">UPDATE 5</div>
      <div class="title-project">ADDED NEW PACKAGES</div>
      <div class="project-date">JAN 27, 2022</div>
      <div class="spacer"></div>
      <div class="description">
        <h2>Summary</h2>
        <p>This week we added the appropriate packages to the Fanuc robot controller
          (thanks Fanuc!) For TCP/IP connection. This allowed us to connect the robot
          to RViz for live monitoring and control. The video below shows an example of
          the simulated robot in RViz moving alongside the physical robot in the lab.
        </p>
        <h2>Video</h2>
        <p>
          <iframe width="100%" height="500" src="https://www.youtube.com/embed/wQM-NK1k36g&list=PLtTq5Z_dEBUsBzKf0L6gjAuuoJ38TnB6J" frameborder="0" allowfullscreen>
          </iframe>
        </p>
      </div>
    </div>

    <div id="update-4" class="work-exp">
      <div class="tag-project">UPDATE 4</div>
      <div class="title-project">CUSTOM OCTOMAP SERVER SET UP</div>
      <div class="project-date">JAN 23, 2022</div>
      <div class="spacer"></div>
      <div class="description">
        <h2>Summary</h2>
        <p>An OctoMap server accessible using RViz was set up to process pointclouds into a usable format. Setup as a node, this process receives the pointcloud and discretizes the points into voxels. These voxels can be imported into RViz as colliders which are used to prevent the robot from hitting seen surfaces, and will later be used in the new pathing scheme. This process connects the collider frame with the robot frame to create an environment with both components simulated simultaneously.</p>
        <h2>Photo</h2>
        <p>
         <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
         </iframe>
        </p>
      </div>
    </div>

    <div id="update-3" class="work-exp">
      <div class="tag-project">UPDATE 3</div>
      <div class="title-project">DESIGNED PROTOTYPE CAD MODELS FOR CAMERA MOUNT</div>
      <div class="project-date">JAN 16, 2022</div>
      <div class="spacer"></div>
      <div class="description">
        <h2>Summary</h2>
        <p>This week models were designed for camera mounts to the robotic arm.
          Two general-use models have been developed for use with a strap to an
          individual link of the robotic arm or to be attached to existing
          fixtures on the sides of the robot.
        </p>
      </div>
    </div>

    <div id="update-2" class="work-exp">
      <div class="tag-project">UPDATE 2</div>
      <div class="title-project">OBTAINED POINT CLOUD IN ROS</div>
      <div class="project-date">JAN 14, 2022</div>
      <div class="spacer"></div>
      <div class="description">
        <h2>Summary</h2>
        <p>Using ROS packages the pointcloud generated by the Intel RealSense was successfully imported. The pointcloud is an array of coloured points which are traced from the origin, or the camera, into a 3D environment based on the depth information. The set of points represents all the surfaces which can be seen from the camera lenses. The pointcloud is accessible using the ROS framework in RVis and is thus ready for further processing.</p>
        <h2>Images</h2>
        <p>
         <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
         </iframe>
        </p>
      </div>
    </div>

    <div id="update-1" class="work-exp">
      <div class="tag-project">UPDATE 1</div>
      <div class="title-project">CONTROLLED ROBOT IN SIMULATION USING ROS</div>
      <div class="project-date">JAN 7, 2022</div>
      <div class="spacer"></div>
      <div class="description">
        <h2>Summary</h2>
        <p>This week we were able to control the Fanuc robot in simulation with
          the same packages that we used for controlling the actual robot. This
          provides us the flexibility to develop appropriate collision algorithms
          in rviz (using C++/Python in Linux), and observe its effect on the
          robot in simulation (using roboguide) running on a windows PC, without
          the need to have access to the real robot. The video below exhibits
          this scenario, with the left screen showing rviz running on a linux
          PC, and Fanuc's Roboguide running on the right screen on a windows
          PC
        </p>
        <h2>Video</h2>
        <p>
          <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
          </iframe>
        </p>
      </div>
    </div>

</div>
</article>
</body>
</html>

    <!--  <div id="update-1" class="work-exp">
        <div class="tag-project">UPDATE 1</div>
        <div class="title-project">LOda LASAN</div>
        <div class="project-date">JAN 2, 2022</div>
        <div class="spacer"></div>
        <div class="description">
          <h2>Summary</h2>
          <p>lalaala</p>
          <h2>Photo/Video</h2>
          <p>
           <iframe width="100%" height="500" src="" frameborder="0" allowfullscreen>
           </iframe>
          </p>
        </div>
      </div>
      --!>
